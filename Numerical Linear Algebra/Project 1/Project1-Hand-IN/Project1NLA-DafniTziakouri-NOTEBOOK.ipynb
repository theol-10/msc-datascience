{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaVQI-uTIKrW"
      },
      "source": [
        "# Project 1 NLA:\n",
        "# Direct methods in optimization with constraints\n",
        "\n",
        "## Dafni Tziakouri\n",
        "20/10/2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqV444I7Jos4"
      },
      "source": [
        "# 2 Solving the KKT system\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGOIj1uoJ4hN"
      },
      "source": [
        "### **T1:** Show that the predictor steps reduces to solve a linear system with matrix MKKT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeTanikLJ_Pv"
      },
      "source": [
        "We are given a function $F:R^N→R^N, N=n+p+2m$,\n",
        "\n",
        "where $F(z) = F(x,γ,λ,s) = 1/2 x^TGx + g^Tx − γ^T(A^T x−b)−λ^T(C^Tx−d−s)$\n",
        "\n",
        "and to solve the following optimization problem $F(z) = 0$ we will use a Newton method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDKJNttmLZYM"
      },
      "source": [
        "We will start with a random point $z_0= (x_0, γ_0, λ_0, s_0)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrPybPrcPzPS"
      },
      "source": [
        "By using the  Newton’s method we want to iteratively improve the guess for z. So, in each iteration, we compute a correction term $δ_z$ using the formula:\n",
        "\n",
        "$F(z_0 + δ_z) ≈ F(z_0) + J_F(z_0) * δ_z$,\n",
        "\n",
        " where $J_F(z_0)$ is the Jacobian matrix of F with respect to z."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2rtjoxxJ7X7"
      },
      "source": [
        "Therefore, we need to solve the following equation $-F(z_0) = J_F(z_0) * δ_z$. This equation represents the KKT conditions for the optimization problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCzP5YHvRpio"
      },
      "source": [
        "The matrix $M_{\\text{KKT}}$ is defined as:\n",
        "\n",
        "$M_{\\text{KKT}} = J_F(z_0)=\n",
        "\\begin{bmatrix}\n",
        "    G & -A & -C & 0 \\\\\n",
        "    -A^T & 0 & 0 & 0 \\\\\n",
        "    -C^T & 0 & 0 & I \\\\\n",
        "    0 & 0 & S & \\Lambda\n",
        "\\end{bmatrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-lOY-ADUE50"
      },
      "source": [
        "We need to solve the linear system:\n",
        "\n",
        "$M_{\\text{KKT}} * \\delta_{z} = -F(z_0)$,\n",
        "\n",
        "where $\\delta_{z} = x_{k+1} - x_k$ the step between the points of the iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQGdoodOV4EK"
      },
      "source": [
        "After obtaining $\\delta_{z}$, we will update our guess for z as:\n",
        "\n",
        "$z_{(k+1)} = z_k + 0.95 * α_k * δ_z$ ,\n",
        "here $α_k$ is a step size that we can adapt or reduce in each iteration to ensure convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah4EcMnsW1T3"
      },
      "source": [
        "To sum up $M_{KKT}$ is vital in the Newton method for optimization as it captures how constraints and objectives respond to variable changes. By solving the linear system $M_{KKT} * δ_z = -F(z_0)$ is pivotal for reaching a solution that meets the KKT conditions and optimizes the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXCCmtMEXrVC"
      },
      "source": [
        "### **C1:** Write down a routine function that implements the step-size substep."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpTLxQdSYV7-"
      },
      "source": [
        "Let's install all the packages we are going to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "diQHr8z2d2E2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import timeit\n",
        "import random\n",
        "import numpy as np\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.linalg import lu_factor, lu_solve\n",
        "from scipy.linalg import ldl, solve_triangular, cholesky, lu_factor, lu_solve\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKiVWt4BXzEX"
      },
      "source": [
        "Firstly, we define the Newton Step algorithm to compute $a$ for the step-size correction substeps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ufbFZMo5Atr2"
      },
      "outputs": [],
      "source": [
        "def Newton_step(lamb0, dlamb, s0, ds):\n",
        "\n",
        "    alpha = 1\n",
        "    index_lamb0 = np.array(np.where(dlamb < 0))\n",
        "\n",
        "    if index_lamb0.size > 0:\n",
        "\n",
        "        alpha = min(alpha,np.min(-lamb0[index_lamb0]/dlamb[index_lamb0]))\n",
        "    index_s0 = np.array(np.where(ds<0))\n",
        "\n",
        "    if index_s0.size > 0:\n",
        "\n",
        "        alpha = min(alpha, np.min(-s0[index_s0]/ds[index_s0]))\n",
        "\n",
        "    return alpha\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qYD2RGb3_RK"
      },
      "source": [
        "## 2.1 Inequality constrains case (i.e. with A = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hqsDoRXcU0O"
      },
      "source": [
        "### **C2:** Write down a program that, for a given n, implements the full algorithm for the test problem. Use the *numpy.linalg.solve* function to solve the KKT linear systems of the predictor and corrector substeps directly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCFQ7MJjckBj"
      },
      "source": [
        "We will create the Karush-Kuhn-Tucker (KKT) matrix, the lambdas and S matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lUuNNndVciCQ"
      },
      "outputs": [],
      "source": [
        "def Matrix_KKT(G, C, n, m, lamb, s):\n",
        "    #arg:\n",
        "    #G : Coefficients for the quadratic objective function.\n",
        "    #C : Constraint matrix.\n",
        "    #n : Number of variables.\n",
        "    #m  Number of constraints.\n",
        "    #lamb : Lagrange multipliers.\n",
        "    #s : Slack variables.\n",
        "\n",
        "    S = np.diag(s)\n",
        "    Lambdas = np.diag(lamb)\n",
        "    eq1 = np.concatenate((G, -C, np.zeros((n, m))), axis = 1)\n",
        "    eq2 = np.concatenate((np.transpose(-C), np.zeros((m, m)), np.identity(m)), axis = 1)\n",
        "    eq3 = np.concatenate((np.zeros((m, n)), S, Lambdas), axis = 1)\n",
        "    Mat = np.concatenate((eq1, eq2, eq3))\n",
        "\n",
        "    #returns: The KKT matrix.\n",
        "    #The diagonal matrix of slack variables (S).\n",
        "    #The diagonal matrix of Lagrange multipliers (Lambdas)\n",
        "\n",
        "    return Mat, S, Lambdas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9It6mlhEM3"
      },
      "source": [
        "Now, we define the $F$ and the $F(z)$ function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GLEv-rk2hDS4"
      },
      "outputs": [],
      "source": [
        "def F(x, G, g):\n",
        "    #this function returns the value of the objective function.\n",
        "    return 0.5 * np.transpose(x).dot(G).dot(x) + np.transpose(g).dot(x)\n",
        "\n",
        "\n",
        "def F_z(x,lamb,s, G, g, C, d):\n",
        "\n",
        "    eq1 = G.dot(x) + g - C.dot(lamb)\n",
        "    eq2 = s + d - np.transpose(C).dot(x)\n",
        "    eq3 = s * lamb\n",
        "    #Returns a vector of equations representing KKT conditions.\n",
        "    return np.concatenate((eq1, eq2, eq3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2KHRBJZh2eA"
      },
      "source": [
        "### **C3:** Write a modification of the previous program C2 to report the computation time of the solution of the test problem for different dimensions n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvwlKu-yiENq"
      },
      "source": [
        "The following algorithm solves $F(z)=0$ using the functions defined above and a modified Newton's method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GZ9Zah32iAnW"
      },
      "outputs": [],
      "source": [
        "def Func_C3(n, maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"Yes\"):\n",
        "    np.random.seed(2) # Set the seed for random number generation\n",
        "    random.seed(2)  # Set the seed for the random module\n",
        "\n",
        "    # We define all the parameters we will need\n",
        "\n",
        "    m = 2*n\n",
        "    x = np.zeros((n))\n",
        "    lamb = np.ones((m))\n",
        "    s = np.ones((m))\n",
        "    z = np.concatenate((x, lamb, s))\n",
        "    G = np.identity(n)\n",
        "    C = np.concatenate((G, - G), axis = 1)\n",
        "    d = np.full((m), - 10)\n",
        "    e = np.ones((m))\n",
        "    g = np.random.normal(0, 1, (n))\n",
        "\n",
        "    # We count the time if asked for when calling the function\n",
        "\n",
        "    if Print_Time == \"Yes\":\n",
        "\n",
        "        Start = time.time()\n",
        "\n",
        "    # Create Matrix_KKT, S and Lambdas with the previously defined function\n",
        "\n",
        "    Mat, S, Lambdas = Matrix_KKT(G, C, n, m, lamb,s)\n",
        "\n",
        "    for i in range(maxIter):\n",
        "\n",
        "        b = -F_z(x, lamb, s, G, g, C, d)\n",
        "        delta = np.linalg.solve(Mat,b)\n",
        "\n",
        "        # We use the step-size correction function previously defined\n",
        "\n",
        "        alpha = Newton_step(lamb, delta[n:n+m], s, delta[n+m:])\n",
        "\n",
        "        # We compute the correction param.\n",
        "\n",
        "        mu = s.dot(lamb) / m\n",
        "        Mu = ((s + alpha * delta[n+m:]).dot(lamb + alpha * delta[n:(n + m)])) / m\n",
        "        sigma = (Mu/mu)**3\n",
        "\n",
        "        # We correct the sub-step\n",
        "\n",
        "        b[(n + m):] = b[(n + m):] - np.diag(delta[(n + m):]*delta[n:(n + m)]).dot(e) + sigma * mu * e\n",
        "\n",
        "        # We find delta by using the linalg function\n",
        "\n",
        "        delta = np.linalg.solve(Mat, b)\n",
        "\n",
        "        #  Step-size correction with delta\n",
        "\n",
        "        alpha = Newton_step(lamb, delta[n:(n + m)], s, delta[(n + m):])\n",
        "\n",
        "        # Let's update the sub-step\n",
        "\n",
        "        z = z + (alpha * delta) * 0.95\n",
        "\n",
        "        # Stopping citeria\n",
        "\n",
        "        if (np.linalg.norm(-b[:n]) < epsilon) or (np.linalg.norm(-b[n:(n + m)]) < epsilon) or (np.abs(mu) < epsilon):\n",
        "\n",
        "            break\n",
        "\n",
        "        # We update the Matrix_KKT\n",
        "\n",
        "        x = z[:n]\n",
        "        lamb = z[n:(n + m)]\n",
        "        s = z[(n + m):]\n",
        "        Mat, S, Lambdas = Matrix_KKT(G, C, n, m, lamb, s)\n",
        "\n",
        "    # We print all the results obtained\n",
        "\n",
        "    if Print_Time == \"Yes\":\n",
        "\n",
        "        End = time.time()\n",
        "\n",
        "        if Print_Results == \"Yes\":\n",
        "\n",
        "            print(\"The computational time for the test problem is equal to: \", End - Start)\n",
        "\n",
        "    if Print_Results == \"Yes\":\n",
        "\n",
        "        print('The minimum of the function was found:', F(x, G, g))\n",
        "        print('The real minimum is:', F(-g, G, g))\n",
        "        print('Iterations needed:', i)\n",
        "        print('Condition number:', np.linalg.cond(Mat))\n",
        "\n",
        "    return(End - Start, i, abs(F(x, G, g) - F(-g, G, g)), np.linalg.cond(Mat))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7JaKPcz7OMn",
        "outputId": "5a0dc049-dce4-4817-ef34-9ed4d557f90a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The computational time for the test problem is equal to:  0.05760073661804199\n",
            "The minimum of the function was found: -7.5524074244333965\n",
            "The real minimum is: -7.552407424433394\n",
            "Iterations needed: 13\n",
            "Condition number: 23.739153102014566\n"
          ]
        }
      ],
      "source": [
        "# We can call the function like this:\n",
        "result = Func_C3(n=10, Print_Time=\"Yes\", Print_Results=\"Yes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htV5BC3IqcLW"
      },
      "source": [
        "We can notice that the computational time for this program is very short, which peovide us information about the effiency or our implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01A_xOJxrlNV"
      },
      "source": [
        "### **T2:** Explain the previous derivations of the different strategies and justify under which assumptions they can be applied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsK1gtQEtLWm"
      },
      "source": [
        "**Strategy 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z489QuWbtcj7"
      },
      "source": [
        "We isolate $δ_s$ from the 3rd row of the $M_{KKT}$ matrix, as:\n",
        "\n",
        "$\\delta_s = \\Lambda^{-1} * (-r_3 - Sd_{\\lambda})$\n",
        "\n",
        "therefore, $\\begin{bmatrix}\n",
        "-C^T & 0 & 1\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "\\delta_x \\\\\n",
        "\\delta_{\\lambda} \\\\\n",
        "\\delta_s\n",
        "\\end{bmatrix}\n",
        "= -r_2$\n",
        "\n",
        "$=> -C^T  \\delta_x + \\delta_s = -r_2$\n",
        "\n",
        "Now we can substitute $δ_s$  from the previous equality:\n",
        "\n",
        "$-C^T\\delta_x + \\Lambda^{-1}*(-r_3 - Sd_{\\lambda}) = -r_2$\n",
        "\n",
        "$=> -C^T\\delta_x - \\Lambda^{-1}(Sd_{\\lambda}) = -r_2 + \\Lambda^{-1}r_3$\n",
        "\n",
        "To solve this equation, $\\Lambda^{-1}$ must be available and invertible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmK5uIsdPLOc"
      },
      "source": [
        "**Strategy 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5AVJ3_1PQGZ"
      },
      "source": [
        "In a similar way we isolate $δ_s$ from the 2nd row of the $M_{KKT}$ matrix, as:\n",
        "\n",
        "$\\delta_s = -r_2 + C^T\\delta_x$\n",
        "\n",
        "and then we substitute this expression for $δ_s$ into the 3rd row:\n",
        "\n",
        "$Sδ_s+Λδ_s= -r_3$\n",
        "$=> Sδ_s+ Λ(-r_2+C^Tδ_x)= - r_3$\n",
        "\n",
        "$=>δ_s = S^{-1}(-r_3 + Λr_2) - S^{-1}ΛC^Tδ_x$\n",
        "\n",
        "Finally, we substitute these expressions into the 1st row to obtain a smaller linear system:\n",
        "\n",
        "$\\hat{G} \\cdot \\delta x = -r_1 - \\hat{r}$\n",
        "\n",
        "This smaller system can be solved using Cholesky factorization and we assume that S is invertible and Λ is available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pivW4nBCSSc7"
      },
      "source": [
        "### **C4:** Write down two programs (modifications of C2) that solve the optimization problem for the test problem using the previous strategies. Report the computational time for different values of n and compare with the results in C3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEKEXjYnvY_"
      },
      "source": [
        "We will modify the program of C2 and C3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ2fu2vJpZIZ"
      },
      "source": [
        "Firstly, we will work with the strategy 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Kb5gtc1XSfFs"
      },
      "outputs": [],
      "source": [
        "# We create the KKT Matrix, lambda and S matrices.\n",
        "\n",
        "def M_KKT_1(G, C, lamb, s):\n",
        "\n",
        "    S = np.diag(s)\n",
        "    Lambdas = np.diag(lamb)\n",
        "    eq1 = np.concatenate((G, -C),axis = 1)\n",
        "    eq2 = np.concatenate((- np.transpose(C), - np.diag(1 / lamb * s)), axis = 1)\n",
        "    Mat = np.concatenate((eq1, eq2))\n",
        "\n",
        "    return Mat, S, Lambdas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "19g1MfoZpGUW"
      },
      "outputs": [],
      "source": [
        "def Func_C4_strategy_1(n, maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"No\"):\n",
        "    np.random.seed(2) # Set the seed for random number generation\n",
        "    random.seed(2)  # Set the seed for the random module\n",
        "\n",
        "    # We define all the parameters we will need\n",
        "\n",
        "    m = 2*n\n",
        "    x = np.zeros((n))\n",
        "    lamb = np.ones((m))\n",
        "    s = np.ones((m))\n",
        "    z = np.concatenate((x,lamb,s))\n",
        "    G = np.identity(n)\n",
        "    C = np.concatenate((G,-G),axis = 1)\n",
        "    d = np.full((m), -10)\n",
        "    e = np.ones((m))\n",
        "    g = np.random.normal(0, 1, (n))\n",
        "\n",
        "    # We count the time if asked for when calling the function\n",
        "\n",
        "    if Print_Time == \"Yes\":\n",
        "      np.random.seed(4)\n",
        "      Start = time.time()\n",
        "\n",
        "    # Create Matrix_KKT, S and Lambdas with the previously defined function\n",
        "\n",
        "    Mat, S, Lambda = M_KKT_1(G, C, lamb, s)\n",
        "\n",
        "    for i in range(maxIter):\n",
        "\n",
        "        lamb_inv = np.diag(1/lamb)\n",
        "\n",
        "        b = F_z(x, lamb, s, G, g, C, d)\n",
        "        r1 = b[:n]\n",
        "        r2 = b[n:(n + m)]\n",
        "        r3 = b[(n + m):]\n",
        "        b = np.concatenate(([- r1, - r2 + 1/ lamb * r3]))\n",
        "\n",
        "        # LDL factorization\n",
        "\n",
        "        L, D, perm = ldl(Mat)\n",
        "        y = solve_triangular(L, b, lower=True, unit_diagonal = True)\n",
        "        delta = solve_triangular(D.dot(np.transpose(L)), y, lower = False)\n",
        "        deltaS = lamb_inv.dot(- r3 - s * delta[n:])\n",
        "        delta = np.concatenate((delta, deltaS))\n",
        "\n",
        "        # We use th step-size correction function previously defined\n",
        "\n",
        "        alpha = Newton_step(lamb, delta[n:(n + m)], s, delta[(n + m):])\n",
        "\n",
        "        # We compute the correction param.\n",
        "\n",
        "        mu = s.dot(lamb) / m\n",
        "        Mu = ((s + alpha * delta[(n + m):]).dot(lamb + alpha * delta[n:(n + m)])) / m\n",
        "        sigma = (Mu / mu) ** 3\n",
        "\n",
        "        # Corrector substep\n",
        "\n",
        "        Ds = np.diag(delta[(n + m):] * delta[n:(n + m)])\n",
        "        b = np.concatenate((-r1, -r2 + lamb_inv.dot(r3 + Ds.dot(e) - sigma * mu * e)))\n",
        "\n",
        "        # We repeat the LDL factorization\n",
        "\n",
        "        y = solve_triangular(L, b, lower = True, unit_diagonal = True)\n",
        "        delta = solve_triangular(D.dot(np.transpose(L)), y, lower = False)\n",
        "        deltaS = lamb_inv.dot(-r3 - Ds.dot(e) + sigma * mu * e - s * delta[n:])\n",
        "        delta = np.concatenate((delta, deltaS))\n",
        "\n",
        "        # Step-size correction substep\n",
        "\n",
        "        alpha = Newton_step(lamb, delta[n:(n + m)], s, delta[(n + m):])\n",
        "\n",
        "        # Update substep\n",
        "\n",
        "        z = z + (alpha * delta) * 0.95\n",
        "\n",
        "        # Stopping citeria\n",
        "\n",
        "        if (np.linalg.norm(- b[:n]) < epsilon) or (np.linalg.norm(- b[n:(n + m)]) < epsilon) or (np.abs(mu) < epsilon):\n",
        "            break\n",
        "\n",
        "        # We update the Matrix_KKT\n",
        "\n",
        "        x = z[:n]\n",
        "        lamb = z[n:(n + m)]\n",
        "        s = z[(n + m):]\n",
        "        Mat, S, Lambda = M_KKT_1(G, C, lamb, s)\n",
        "\n",
        "    # We print all the results obtained\n",
        "\n",
        "    if Print_Time == \"Yes\":\n",
        "\n",
        "        End = time.time()\n",
        "\n",
        "        if Print_Results == \"Yes\":\n",
        "\n",
        "            print(\"The computational time for the test problem is equal to: \", End - Start)\n",
        "\n",
        "    if Print_Results == \"Yes\":\n",
        "\n",
        "        print('The minimum of the function was found:', F(x, G, g))\n",
        "        print('The real minimum is:', F(-g, G, g))\n",
        "        print('Iterations needed:', i)\n",
        "        print('Condition number:', np.linalg.cond(Mat))\n",
        "\n",
        "    return(End - Start, i, abs(F(x, G, g) - F(-g, G, g)), np.linalg.cond(Mat))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE42og_Apy2B",
        "outputId": "56b74f37-4624-4c16-ddc1-110c4e799794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The computational time for the test problem is equal to:  0.02399277687072754\n",
            "The minimum of the function was found: -7.5524074244333965\n",
            "The real minimum is: -7.552407424433394\n",
            "Iterations needed: 13\n",
            "Condition number: 28917368231557.566\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.02399277687072754, 13, 2.6645352591003757e-15, 28917368231557.566)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We just call the function once to check our values\n",
        "#n=10\n",
        "Func_C4_strategy_1(n=10, maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"Yes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNxWv4CVr0yn"
      },
      "source": [
        "Now, let's work with the strategy 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ycsci-CosBs1"
      },
      "outputs": [],
      "source": [
        "# We create the KKT Matrix, lambda and S matrices.\n",
        "\n",
        "def M_KKT_2(G, C, lamb, s):\n",
        "\n",
        "    S = np.diag(s)\n",
        "    Lambdas = np.diag(lamb)\n",
        "    Mat = G + C.dot(np.diag(1 / s * lamb)).dot(np.transpose(C))\n",
        "\n",
        "    return Mat, Lambdas, S\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "flOrlQvesPuG"
      },
      "outputs": [],
      "source": [
        "def Func_C4_strategy_2(n, maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"No\"):\n",
        "    np.random.seed(2) # Set the seed for random number generation\n",
        "    random.seed(2)  # Set the seed for the random module\n",
        "\n",
        "    # We define all the parameters we will need\n",
        "\n",
        "    m = 2 * n\n",
        "    x = np.zeros((n))\n",
        "    lamb = np.ones((m))\n",
        "    s = np.ones((m))\n",
        "    z = np.concatenate((x, lamb, s))\n",
        "    G = np.identity(n)\n",
        "    C = np.concatenate((G, - G),axis = 1)\n",
        "    d = np.full((m), - 10)\n",
        "    e = np.ones((m))\n",
        "    g = np.random.normal(0, 1, (n))\n",
        "\n",
        "    # We count the time if asked for when calling the function\n",
        "\n",
        "    if Print_Time == \"Yes\":\n",
        "        np.random.seed(4)\n",
        "        Start = time.time()\n",
        "\n",
        "    # Create Matrix_KKT, S and Lambdas with the previously defined function\n",
        "\n",
        "    Ghat, Lambda, S  = M_KKT_2(G, C, lamb,s)\n",
        "\n",
        "    for i in range(maxIter):\n",
        "\n",
        "        S_inv = np.diag(1 / s)\n",
        "\n",
        "        b = F_z(x, lamb, s, G, g, C, d)\n",
        "        r1 = b[:n]\n",
        "        r2 = b[n:(n + m)]\n",
        "        r3 = b[(n + m):]\n",
        "        rhat = - C.dot(np.diag(1 / s)).dot((- r3 + lamb * r2))\n",
        "        b = - r1 - rhat\n",
        "\n",
        "        # Cholesky factorization\n",
        "\n",
        "        Cholesk = cholesky(Ghat, lower = True)\n",
        "        y = solve_triangular(Cholesk, b, lower=True)\n",
        "        delta_x = solve_triangular(np.transpose(Cholesk), y)\n",
        "        delta_lamb = S_inv.dot((- r3 + lamb * r2)) - S_inv.dot(Lambda.dot(np.transpose(C)).dot(delta_x))\n",
        "        delta_s = - r2 + np.transpose(C).dot(delta_x)\n",
        "        delta = np.concatenate((delta_x,delta_lamb, delta_s))\n",
        "\n",
        "        # We use th step-size correction function previously defined\n",
        "\n",
        "        alpha = Newton_step(lamb, delta[n:(n + m)], s, delta[(n + m):])\n",
        "\n",
        "        # We compute the correction param.\n",
        "\n",
        "        mu = s.dot(lamb) / m\n",
        "        Mu = ((s + alpha * delta[(n + m):]).dot(lamb + alpha * delta[n:(n + m)])) / m\n",
        "        sigma = (Mu / mu) ** 3\n",
        "\n",
        "        # Corrector substep\n",
        "\n",
        "        Ds_Dlamb = np.diag(delta[n+m:]*delta[n:n+m])\n",
        "        b = -r1-(-C.dot(np.diag(1/s)).dot((-r3-Ds_Dlamb.dot(e)+sigma*mu*e+lamb*r2)))\n",
        "\n",
        "        # We repeat the Cholesky factorization again\n",
        "\n",
        "        y = solve_triangular(Cholesk,b,lower=True)\n",
        "        delta_x = solve_triangular(np.transpose(Cholesk),y)\n",
        "        delta_lamb = S_inv.dot(-r3-Ds_Dlamb.dot(e)+sigma*mu*e+lamb*r2)-S_inv.dot(lamb*(np.transpose(C).dot(delta_x)))\n",
        "        delta_s = - r2 + np.transpose(C).dot(delta_x)\n",
        "        delta = np.concatenate((delta_x,delta_lamb, delta_s))\n",
        "\n",
        "        # Step-size correction substep\n",
        "\n",
        "        alpha = Newton_step(lamb, delta[n:(n + m)],s,delta[(n + m):])\n",
        "\n",
        "        # Update substep\n",
        "\n",
        "        z = z + (alpha * delta) * 0.95\n",
        "\n",
        "        # Stopping citeria\n",
        "\n",
        "        if (np.linalg.norm(- r1) < epsilon) or (np.linalg.norm(-r2) < epsilon) or (np.abs(mu) < epsilon):\n",
        "\n",
        "            break\n",
        "\n",
        "        # We update the Matrix_KKT\n",
        "\n",
        "        x = z[:n]\n",
        "        lamb = z[n:(n + m)]\n",
        "        s = z[(n + m):]\n",
        "        Ghat, Lambda, S = M_KKT_2(G, C, lamb,s)\n",
        "\n",
        "    if Print_Time == \"Yes\":\n",
        "\n",
        "        End = time.time()\n",
        "\n",
        "        if Print_Results == \"Yes\":\n",
        "\n",
        "            print(\"Computation time for the test problem: \", End - Start)\n",
        "\n",
        "    if Print_Results == \"Yes\":\n",
        "\n",
        "        print('The minimum of the function was found:', F(x, G, g))\n",
        "        print('The real minimum is:', F(-g, G, g))\n",
        "        print('Iterations needed:', i)\n",
        "        print('Condition number:', np.linalg.cond(Ghat))\n",
        "\n",
        "    return(End - Start, i, abs(F(x, G, g) - F(-g, G, g)), np.linalg.cond(Ghat))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZjQba_3sqsj",
        "outputId": "9d22813b-477c-4cc4-e2d9-f4541bb84592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computation time for the test problem:  0.010763883590698242\n",
            "The minimum of the function was found: -7.5524074244333965\n",
            "The real minimum is: -7.552407424433394\n",
            "Iterations needed: 13\n",
            "Condition number: 1.0000000000001306\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.010763883590698242, 13, 2.6645352591003757e-15, 1.0000000000001306)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We just call the function once to check our values\n",
        "#n=10\n",
        "Func_C4_strategy_2(n = 10, Print_Time = \"Yes\", Print_Results = \"Yes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr_YakGru7YR"
      },
      "source": [
        "We will compare the results of each function/program (C3, C4_LDL, C4_Cholesky) for different values of n (10, 50, 100):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbHhBKnOvN5F"
      },
      "source": [
        "*n=10*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUtOwtQtvSj-",
        "outputId": "6298d137-979c-42ac-a946-fa79f276944e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C3\n",
            "The computational time for the test problem is equal to:  0.08610129356384277\n",
            "The minimum of the function was found: -7.5524074244333965\n",
            "The real minimum is: -7.552407424433394\n",
            "Iterations needed: 13\n",
            "Condition number: 23.739153102014566\n",
            "\n",
            "\n",
            "C4_LDL\n",
            "The computational time for the test problem is equal to:  0.02613210678100586\n",
            "The minimum of the function was found: -7.5524074244333965\n",
            "The real minimum is: -7.552407424433394\n",
            "Iterations needed: 13\n",
            "Condition number: 28917368231557.566\n",
            "\n",
            "\n",
            "C4_Cholesky\n",
            "Computation time for the test problem:  0.014591217041015625\n",
            "The minimum of the function was found: -7.5524074244333965\n",
            "The real minimum is: -7.552407424433394\n",
            "Iterations needed: 13\n",
            "Condition number: 1.0000000000001306\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.014591217041015625, 13, 2.6645352591003757e-15, 1.0000000000001306)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"C3\")\n",
        "Func_C3(n=10, Print_Time=\"Yes\", Print_Results=\"Yes\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"C4_LDL\")\n",
        "Func_C4_strategy_1(n=10, maxIter=100, epsilon=10e-16, Print_Time=\"Yes\", Print_Results=\"Yes\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"C4_Cholesky\")\n",
        "Func_C4_strategy_2(n=10, maxIter=100, epsilon=10e-16, Print_Time=\"Yes\", Print_Results=\"Yes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6Vr9E4UyHxG"
      },
      "source": [
        "*n=50*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0boYCcZyFtw",
        "outputId": "e02ab407-1fc7-42d7-c520-6f2d2e5c7411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The computational time for the test problem is equal to:  0.42031097412109375\n",
            "The minimum of the function was found: -27.56263587399191\n",
            "The real minimum is: -27.562635873991923\n",
            "Iterations needed: 15\n",
            "Condition number: 24.328402008614216\n",
            "\n",
            "\n",
            "C4_LDL\n",
            "The computational time for the test problem is equal to:  0.09992551803588867\n",
            "The minimum of the function was found: -27.56263587399191\n",
            "The real minimum is: -27.562635873991923\n",
            "Iterations needed: 15\n",
            "Condition number: 7715279992153.374\n",
            "\n",
            "\n",
            "C4_Cholesky\n",
            "Computation time for the test problem:  0.04391193389892578\n",
            "The minimum of the function was found: -27.56263587399191\n",
            "The real minimum is: -27.562635873991923\n",
            "Iterations needed: 15\n",
            "Condition number: 1.0000000000018008\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.04391193389892578, 15, 1.4210854715202004e-14, 1.0000000000018008)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"C3\")\n",
        "Func_C3(n=50, Print_Time=\"Yes\", Print_Results=\"Yes\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"C4_LDL\")\n",
        "Func_C4_strategy_1(n=50, maxIter=100, epsilon=10e-16, Print_Time=\"Yes\", Print_Results=\"Yes\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"C4_Cholesky\")\n",
        "Func_C4_strategy_2(n=50, maxIter=100, epsilon=10e-16, Print_Time=\"Yes\", Print_Results=\"Yes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8rMsklkyQzN"
      },
      "source": [
        "*n=100*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll5RkAUYyTjR",
        "outputId": "43467de7-dd79-477f-e821-e6ed87b2dc4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The computational time for the test problem is equal to:  0.6173884868621826\n",
            "The minimum of the function was found: -54.31027476317925\n",
            "The real minimum is: -54.31027476317925\n",
            "Iterations needed: 14\n",
            "Condition number: 24.773379328575576\n",
            "\n",
            "\n",
            "C4_LDL\n",
            "The computational time for the test problem is equal to:  0.3144383430480957\n",
            "The minimum of the function was found: -54.31027476317925\n",
            "The real minimum is: -54.31027476317925\n",
            "Iterations needed: 14\n",
            "Condition number: 23750065446450.97\n",
            "\n",
            "\n",
            "C4_Cholesky\n",
            "Computation time for the test problem:  0.10594987869262695\n",
            "The minimum of the function was found: -54.31027476317925\n",
            "The real minimum is: -54.31027476317925\n",
            "Iterations needed: 14\n",
            "Condition number: 1.000000000000211\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.10594987869262695, 14, 0.0, 1.000000000000211)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"C3\")\n",
        "Func_C3(n=100, Print_Time=\"Yes\", Print_Results=\"Yes\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"C4_LDL\")\n",
        "Func_C4_strategy_1(n=100, maxIter=100, epsilon=10e-16, Print_Time=\"Yes\", Print_Results=\"Yes\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"C4_Cholesky\")\n",
        "Func_C4_strategy_2(n=100, maxIter=100, epsilon=10e-16, Print_Time=\"Yes\", Print_Results=\"Yes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_cjL1O40uDB"
      },
      "source": [
        "We notice that for all values of n, the C4_Cholesky method has the shortest computation time, making it the fastest among the three methods.\n",
        "\n",
        "Also, the number of iterations required for convergence is relatively consistent across all three methods for a given n. This suggests that the number of iterations required doesn't vary significantly with n.\n",
        "\n",
        "Furthermore, the C4_LDL method shows high condition numbers for all values of n. This can make the numerical solution unstable and less reliable. On the other hand, C4_Cholesky method consistently reports a condition number very close to 1, suggesting that the Cholesky factorization method used in this approach provides stable and well-conditioned results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQwWTPFs3ryK"
      },
      "source": [
        "## 2.2 General case (with equality and inequality constrains)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DELdtBWC4v-N"
      },
      "source": [
        "### **C5:** Write down a program that solves the optimization problem for the general case. Use numpy.linalg.solve function. Read the data of the optimization problems from the files (available at the Campus Virtual). Each problem consists on a collection of files: G.dad, g.dad, A.dad, b.dad, C.dad and d.dad. They contain the corresponding data in coordinate format. Take as initial condition $x_0 = (0, . . . , 0)$ and $s_0 = γ_0 = λ_0 = (1, . . . , 1)$ for all problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye9uY2gU54Fz"
      },
      "source": [
        "We will first create the functions that will help us import our vectors and matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kO8zBDOO5o3F"
      },
      "outputs": [],
      "source": [
        "def ReadMatrix(source, shape, symm=False):\n",
        "\n",
        "    matrix = np.zeros(shape)\n",
        "\n",
        "    with open(source, \"r\") as file:\n",
        "\n",
        "        a = file.readlines()\n",
        "\n",
        "    for line in a:\n",
        "\n",
        "        row, column, value = line.strip().split()\n",
        "        row = int(row)\n",
        "        column = int(column)\n",
        "        value = float(value)\n",
        "        matrix[row - 1, column - 1] = value\n",
        "\n",
        "        if symm == True:\n",
        "\n",
        "            matrix[column - 1, row - 1] = value\n",
        "\n",
        "    return matrix\n",
        "\n",
        "\n",
        "def ReadVector(source, n):\n",
        "\n",
        "    v = np.zeros(n)\n",
        "\n",
        "    with open(source, \"r\") as file:\n",
        "\n",
        "        a = file.readlines()\n",
        "\n",
        "    for line in a:\n",
        "\n",
        "        idx, value = line.strip().split()\n",
        "        idx = int(idx)\n",
        "        value = float(value)\n",
        "        v[idx - 1] = value\n",
        "\n",
        "    return v\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SaqeUc-N5qzp"
      },
      "outputs": [],
      "source": [
        "# We define the Matrix KKT for the exercise\n",
        "\n",
        "def M_KKT_C5(G, C, A, n, m, p, lamb,s):\n",
        "\n",
        "    S = np.diag(s)\n",
        "    Lambda = np.diag(lamb)\n",
        "    temp1 = np.concatenate((G, -A, -C, np.zeros((n, m))),axis = 1)\n",
        "    temp2 = np.concatenate((- np.transpose(A),np.zeros((p, p + 2 * m))), axis = 1)\n",
        "    temp3 = np.concatenate((np.transpose(- C),np.zeros((m, p + m)), np.identity(m)), axis = 1)\n",
        "    temp4 = np.concatenate((np.zeros((m, n + p)), S, Lambda), axis = 1)\n",
        "    M = np.concatenate((temp1, temp2, temp3, temp4))\n",
        "\n",
        "    return M, S, Lambda\n",
        "\n",
        "\n",
        "\n",
        "def funC5(A, G, C, g, x, gamma, lamb, s, bm, d):\n",
        "\n",
        "    comp1 = G.dot(x)+g-A.dot(gamma)-C.dot(lamb)\n",
        "    comp2 = bm-np.transpose(A).dot(x)\n",
        "    comp3 = s+d-np.transpose(C).dot(x)\n",
        "    comp4 = s*lamb\n",
        "\n",
        "    return np.concatenate((comp1,comp2,comp3,comp4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0hxfV8EJ7xv-"
      },
      "outputs": [],
      "source": [
        "def Function_C5(maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"No\", Data = r\"optpr1\"):\n",
        "    \n",
        "    np.random.seed(2) # Set the seed for random number generation\n",
        "    random.seed(2)  # Set the seed for the random module\n",
        "\n",
        "    # We define all the parameters we will need\n",
        "\n",
        "    n = int(np.loadtxt(Data + \"/g.dad\")[:,0][-1])\n",
        "    p = n // 2\n",
        "    m = 2 * n\n",
        "    A = ReadMatrix(Data + \"/A.dad\", (n, p))\n",
        "    bm = ReadVector(Data + \"/b.dad\", p)\n",
        "    C = ReadMatrix(Data + \"/C.dad\", (n, m))\n",
        "    d = ReadVector(Data + \"/d.dad\", m)\n",
        "    e = np.ones((m))\n",
        "    G = ReadMatrix(Data + \"/g.dad\", (n, n), True)\n",
        "    g = np.zeros(n)\n",
        "    x = np.zeros((n))\n",
        "    gamma = np.ones((p))\n",
        "    lamb = np.ones((m))\n",
        "    s = np.ones((m))\n",
        "    z = np.concatenate((x,gamma,lamb,s))\n",
        "\n",
        "    if Print_Time == \"Yes\":\n",
        "        np.random.seed(2)\n",
        "        Start = time.time()\n",
        "\n",
        "    # Create Matrix_KKT, S and Lambdas with the previously defined function\n",
        "\n",
        "    Mat, S, Lambda = M_KKT_C5(G, C, A, n, m, p, lamb, s)\n",
        "\n",
        "    for i in range(maxIter):\n",
        "\n",
        "        b = - funC5(A, G, C, g, x, gamma, lamb, s, bm, d)\n",
        "        delta = np.linalg.solve(Mat, b)\n",
        "\n",
        "        # Step-size correction substep\n",
        "\n",
        "        alpha = Newton_step(lamb,delta[(n + p) : (n + p + m)], s, delta[(n + m + p):])\n",
        "\n",
        "        # Compute correction parameters\n",
        "\n",
        "        mu = s.dot(lamb) / m\n",
        "        Mu = ((s + alpha * delta[(n + m + p):]).dot(lamb + alpha * delta[(n + p):(n + m + p)])) / m\n",
        "        sigma = (Mu / mu) ** 3\n",
        "\n",
        "        # Corrector substep\n",
        "\n",
        "        b[(n + m + p):] = b[(n + p + m):] - np.diag(delta[(n + p + m):] * delta[(n + p) : (n + p + m)]).dot(e) + sigma * mu * e\n",
        "        delta = np.linalg.solve(Mat, b)\n",
        "\n",
        "        # Step-size correction substep\n",
        "\n",
        "        alpha = Newton_step(lamb, delta[(n + p):(n + p + m)], s, delta[(n + m + p):])\n",
        "\n",
        "        # We update the substep\n",
        "\n",
        "        z = z + 0.95 * alpha * delta\n",
        "\n",
        "        # The stopping criteria\n",
        "\n",
        "        if (np.linalg.norm(- b[:n]) < epsilon) or (np.linalg.norm(- b[n:(n + m)]) < epsilon) or (np.linalg.norm(- b[(n + p):(n + p + m)]) < epsilon) or (np.abs(mu) < epsilon):\n",
        "\n",
        "            break\n",
        "\n",
        "        # We update the Matrix KKT\n",
        "\n",
        "        x = z[:n]\n",
        "        gamma = z[n:(n+p)]\n",
        "        lamb = z[(n + p):(n + m + p)]\n",
        "        s = z[(n + m + p):]\n",
        "        Mat, S, Lambda = M_KKT_C5(G, C, A, n, m, p, lamb,s)\n",
        "\n",
        "    condition_number = np.linalg.cond(Mat)\n",
        "\n",
        "    if Print_Time == \"Yes\":\n",
        "\n",
        "        End = time.time()\n",
        "\n",
        "        if Print_Results == \"Yes\":\n",
        "\n",
        "            print(\"Computation time: \",End - Start)\n",
        "\n",
        "    if Print_Results == \"Yes\":\n",
        "\n",
        "        print('Minimum was found:', F(x, G, g))\n",
        "        print('Condition number:', condition_number)\n",
        "        print('Iterations needed:', i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "hReysJEO9cWR",
        "outputId": "e4050203-136d-4b8f-bb35-e0bbc4e0b5f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For matrices and vectors from optpr1, the obtained results are the following:\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computation time:  2.1085500717163086\n",
            "Minimum was found: 11590.718119426767\n",
            "Condition number: 1.9495161760426004e+18\n",
            "Iterations needed: 25\n",
            "\n",
            "\n",
            "For matrices and vectors from optpr2, the obtained results are the following:\n",
            "\n",
            "\n",
            "Computation time:  577.6200385093689\n",
            "Minimum was found: 1087511.5673215014\n",
            "Condition number: 5.554413718885413e+18\n",
            "Iterations needed: 28\n"
          ]
        }
      ],
      "source": [
        "print(\"For matrices and vectors from optpr1, the obtained results are the following:\")\n",
        "print(\"\\n\")\n",
        "Function_C5(maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"Yes\", Data = r\"optpr1\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"For matrices and vectors from optpr2, the obtained results are the following:\")\n",
        "print(\"\\n\")\n",
        "Function_C5(maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"Yes\", Data = r\"optpr2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**We obtained that:**\n",
        "\n",
        "**1.** *Optpr2* requires significantly more computational time compared to *optpr1*, indicating that *optpr2* is more computationally intensive.\n",
        "\n",
        "**2.** *Optpr1* has a lower minimum objective function value than *optpr2*, suggesting that it is an easier optimization problem to solve.\n",
        "\n",
        "**3.** The condition number of the KKT matrix for *optpr2* is much higher than that of *optpr1*, indicating that *optpr2* is a more ill-conditioned problem, which can make optimization more challenging.\n",
        "\n",
        "**4.** While both problems converge within the specified tolerance, *optpr2* requires slightly more iterations to reach convergence than *optpr1*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **T3:** Isolate $δ_s$ from the 4th row of MKKT and substitute into the 3rd row. Justify that this procedure leads to a linear system with a symmetric matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's write down the equations for the general case:\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{Equation 1:} & \\quad Gδ_x-Aδ_λ-Cδ_λ= -r_1 \\\\\n",
        "\\text{Equation 2:} & \\quad -Aδ_x= -r_2 \\\\\n",
        "\\text{Equation 3:} & \\quad δ_s- C^Tδ_x= -r_3 \\\\\n",
        "\\text{Equation 4:} & \\quad Λδ_s+ Sδ_λ= -r_4 \\\\\n",
        "\\end{align*}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will follow the same procedure that has been demonstrated in T2, but now isolating $δ_s$ from the 4th row instead of the 2nd and 3rd row. So, we get the following equation for $δ_s$:\n",
        "$$δ_s= - Λ^{-1}(r_4+Sδ_λ)$$\n",
        "\n",
        "Now we will substitute $δ_s$ in the 3rd row and we will get the following equation:\n",
        "$$-C^Tδ_x- Λ^{-1}(r_4+Sδ_λ)= -r_3$$\n",
        "\n",
        "If we convert this to a matrix form, we get the following result:\n",
        "\\begin{align*}\n",
        "\\begin{pmatrix}\n",
        "G & -A & -C \\\\\n",
        "-A^T & 0 & 0 \\\\\n",
        "-C^T & 0 & -S\\Lambda^{-1}\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "\\delta_x \\\\\n",
        "\\delta_\\lambda \\\\\n",
        "\\delta_s\n",
        "\\end{pmatrix}\n",
        "&=\n",
        "\\begin{pmatrix}\n",
        "-r_1 \\\\\n",
        "-r_2 \\\\\n",
        "\\Lambda^{-1}r_4 -r_3\n",
        "\\end{pmatrix}\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In conclusion, the final matrix resulting from the procedure is indeed symmetric because is guaranteed by the properties of the matrices involved. Specifically, the matrix $-SΛ^{-1}$ is always symmetric because it arises from the product of two diagonal matrices. \n",
        "As it was defined in the start of this project, matrix $G ∈ R^{n*n}$ is a symmetric semidefinite positive matrix, and the matrix we have found matches the characteristics of matrix $G$, further confirming its symmetry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **C6:** Implement a routine that uses LDLT to solve the optimizations problems (in C5) and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We define the Matrix KKT for the exercise\n",
        "\n",
        "def M_KKT_C6(G, C, A, n, m, p, lamb,s):\n",
        "    \n",
        "    S = np.diag(s)\n",
        "    Lambda = np.diag(lamb)\n",
        "    temp1 = np.concatenate((G,- A, - C),axis = 1)\n",
        "    temp2 = np.concatenate((- np.transpose(A), np.zeros((p, p + m))), axis = 1)\n",
        "    temp3 = np.concatenate((- np.transpose(C), np.zeros((m, p)), np.diag(-1 / lamb * s)), axis = 1)\n",
        "    Mat = np.concatenate((temp1, temp2, temp3))\n",
        "    \n",
        "    return Mat, S, Lambda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Function_C6(maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"No\", Data = \"optpr1\"):\n",
        "    np.random.seed(2) # Set the seed for random number generation\n",
        "    random.seed(2)  # Set the seed for the random module\n",
        "\n",
        "    # We define all the parameters we will need\n",
        "    \n",
        "    n = int(np.loadtxt(Data + \"/G.dad\")[:,0][-1])\n",
        "    p = n // 2\n",
        "    m = 2 * n\n",
        "    A = ReadMatrix(Data + \"/A.dad\", (n, p))\n",
        "    bm = ReadVector(Data + \"/b.dad\", p)\n",
        "    C = ReadMatrix(Data + \"/C.dad\", (n, m))\n",
        "    d = ReadVector(Data + \"/d.dad\", m)\n",
        "    e = np.ones((m))\n",
        "    G = ReadMatrix(Data + \"/G.dad\", (n, n), True)\n",
        "    g = np.zeros((n))\n",
        "    x = np.zeros((n))\n",
        "    gamma = np.ones((p))\n",
        "    lamb = np.ones((m))\n",
        "    s = np.ones((m))\n",
        "    z = np.concatenate((x, gamma, lamb, s))\n",
        "    \n",
        "    if Print_Time == \"Yes\":\n",
        "        np.random.seed(2)\n",
        "        Start = time.time()\n",
        "\n",
        "    # Create Matrix_KKT, S and Lambdas with the previously defined function \n",
        "    \n",
        "    Mat,S,Lamb = M_KKT_C6(G, C, A, n, m, p, lamb,s)\n",
        "\n",
        "    for i in range(maxIter):\n",
        "        \n",
        "        lamb_inv = np.diag(1/lamb)\n",
        "\n",
        "        b = funC5(A, G, C, g, x, gamma, lamb, s, bm, d)\n",
        "        r1, r2, r3, r4 = b[:n], b[n:n+p], b[n+p:n+p+m], b[n+p+m:]\n",
        "        b = np.concatenate(([-r1,-r2,-r3+1/lamb*r4]))\n",
        "\n",
        "        # LDL factorization\n",
        "        \n",
        "        L, D, perm = ldl(Mat)\n",
        "        y = np.linalg.solve(L, b)\n",
        "        delta = np.linalg.solve(D.dot(np.transpose(L)), y)\n",
        "        deltaS = lamb_inv.dot(- r4 - s * delta[(n + p):])\n",
        "        delta = np.concatenate((delta, deltaS))\n",
        "\n",
        "        # Step-size correction substep\n",
        "        \n",
        "        alpha = Newton_step(lamb,delta[(n + p) : (n + p + m)], s, delta[(n + m + p):])\n",
        "\n",
        "        # We compute the correction parameters\n",
        "        \n",
        "        mu = s.dot(lamb) / m\n",
        "        Mu = ((s + alpha * delta[(n + m + p):]).dot(lamb + alpha * delta[(n + p):(n + m + p)])) / m\n",
        "        sigma = (Mu / mu) ** 3\n",
        "\n",
        "        # Substep corrector\n",
        "        \n",
        "        Ds = np.diag(delta[(n + p + m):] * delta[(n + p):(n + p + m)])\n",
        "        b = np.concatenate((- r1, - r2, - r3 + lamb_inv.dot(r4 + Ds.dot(e) - sigma * mu * e)))\n",
        "\n",
        "        # Repeat LDL factorization\n",
        "        \n",
        "        y = np.linalg.solve(L, b)\n",
        "        delta = np.linalg.solve(D.dot(np.transpose(L)), y)\n",
        "        deltaS = lamb_inv.dot(- r4 - Ds.dot(e) + sigma * mu * e - s * delta[(n + p):])\n",
        "        delta = np.concatenate((delta, deltaS))\n",
        "\n",
        "        # Step-size correction substep\n",
        "        \n",
        "        alpha = Newton_step(lamb, delta[(n + p):(n + p + m)], s, delta[(n + m + p):])\n",
        "\n",
        "        # We update the substep\n",
        "        \n",
        "        z = z + 0.95 * alpha * delta\n",
        "\n",
        "        # The stopping criteria\n",
        "        \n",
        "        if (np.linalg.norm(- b[:n]) < epsilon) or (np.linalg.norm(- b[n:(n + m)]) < epsilon) or (np.linalg.norm(- b[(n + p):(n + p + m)]) < epsilon) or (np.abs(mu) < epsilon):\n",
        "            \n",
        "            break\n",
        "\n",
        "        # We update tha  Matrix KKT\n",
        "        \n",
        "        x = z[:n]\n",
        "        gamma = z[n:(n+p)]\n",
        "        lamb = z[(n + p):(n + m + p)]\n",
        "        s = z[(n + m + p):]\n",
        "        Mat,Lamb,S = M_KKT_C6(G, C, A, n, m, p, lamb,s)\n",
        "        \n",
        "    condition_number = np.linalg.cond(Mat)\n",
        "    \n",
        "    if Print_Time == \"Yes\":\n",
        "        \n",
        "        End = time.time()\n",
        "        \n",
        "        if Print_Results == \"Yes\":\n",
        "            \n",
        "            print(\"Computation time: \",End - Start)\n",
        "            \n",
        "    if Print_Results == \"Yes\":\n",
        "        \n",
        "        print('Minimum was found:', F(x, G, g))\n",
        "        print('Condition number:', condition_number)\n",
        "        print('Iterations needed:', i)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For matrices and vectors from optpr1, the obtained results where the following:\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computation time:  2.8469667434692383\n",
            "Minimum was found: 11590.718119426772\n",
            "Condition number: 6.375699758041506e+21\n",
            "Iterations needed: 31\n",
            "\n",
            "\n",
            "For matrices and vectors from optpr2, the obtained results where the following:\n",
            "\n",
            "\n",
            "Computation time:  537.7279386520386\n",
            "Minimum was found: 1087511.5673214972\n",
            "Condition number: 8.859261568310938e+22\n",
            "Iterations needed: 34\n"
          ]
        }
      ],
      "source": [
        "print(\"For matrices and vectors from optpr1, the obtained results where the following:\") \n",
        "print(\"\\n\")\n",
        "Function_C6(maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"Yes\", Data = \"optpr1\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"For matrices and vectors from optpr2, the obtained results where the following:\")\n",
        "print(\"\\n\")\n",
        "Function_C6(maxIter=100, epsilon=10e-16, Print_Time = \"Yes\", Print_Results = \"Yes\", Data = \"optpr2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In C5 algorithm we use the *numpy.linalg.solve* factorization function and in C6 algorithm the LDLT factorization function. Let's compare these two approaches:\n",
        "\n",
        "1. In general, in C5 algorithm we had shorter computation times compared to C6 algorithm, because  the additional LDLT factorization steps can be computationally expensive.\n",
        "\n",
        "2. The minimum values found in both C5 and C6 algorithms are similar. It indicates that both methods successfully converged to the same or very close optima.\n",
        "\n",
        "3. The condition number of the KKT matrix in C5 and C6 algorithms differs significantly. C6 algorithm typically results in a much higher condition number,this can indicate that the matrix is ill-conditioned and that small changes in the input data or the optimization problem formulation can lead to significant changes in the solution. This implies that C6 algorithm might produce less stable solutions for certain problem instances.\n",
        "\n",
        "4. In C6 algorithm it required more iterations to converge than in C5 algorithm. This could be due to the additional LDLT factorization and the step-size correction substeps involved in C6. More iterations generally translate to longer computation times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To conclude, both numpy.linalg.solve factorization function and LDLT factorization function are capable of solving optimization problems, but they have different characteristics. \n",
        "\n",
        "C5 algorithm is relatively faster and might be preferred for problems where computational speed is a priority. On the other hand, C6 algorithm utilizes LDLT factorization, which can be more numerically stable for some problems. It might be preferred for problems where the condition number of the KKT matrix \n",
        "is a concern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a final project comment, we can say that we have seen that numpy.linalg.solve factorization function is the fastest way to get a result, while Cholesky is the most precise method and the one with a better condition number. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
