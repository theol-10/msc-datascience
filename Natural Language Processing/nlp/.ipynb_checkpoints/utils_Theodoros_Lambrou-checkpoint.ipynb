{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18ace03-6aef-4bb6-a4f4-affdf4d81f00",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Theodoros Lambrou**\n",
    "\n",
    "This notebook explains the utility functions I contributed to `utils.py` for this assignment, alongside creating the project structure and building the baseline pipeline. These functions handle basic preprocessing, lexical similarity, early semantic similarity, data splitting.\n",
    "These utility functions formed the foundation for preprocessing and baseline modeling in this assignment. They are based on simplicity, interpretability and are based on the course guidelines.\n",
    "\n",
    "---\n",
    "\n",
    "### `clean_text(text)`\n",
    "Cleans raw text by lowercasing, removing punctuation, and normalizing whitespace. This is essential for ensuring that downstream NLP features aren't affected by superficial formatting.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "clean_text(\"  This is an EXAMPLE !!  \")  # Output: 'this is an example'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `jaccard_similarity(q1, q2)`\n",
    "Calculates the Jaccard similarity between the sets of words in two questions. This metric measures lexical overlap, a simple and interpretable feature.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "jaccard_similarity(\"what is ai\", \"what is artificial intelligence\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `extract_basic_features(df)`\n",
    "Takes a DataFrame of question pairs, applies `clean_text()` to both questions, and computes their Jaccard similarity. Returns a new DataFrame with a single column: `'jaccard'`.\n",
    "\n",
    "This was used to build our baseline logistic regression model.\n",
    "\n",
    "---\n",
    "\n",
    "### `tfidf_cosine_similarity(q1, q2, vectorizer=None)`\n",
    "Computes cosine similarity between two questions using TF-IDF vectors. Optionally accepts a shared vectorizer.\n",
    "\n",
    "Used to captures semantic similarity based on token frequency and importance.\n",
    "\n",
    "---\n",
    "\n",
    "### `load_and_split_data()`\n",
    "Implemented the required data split logic based on the assignment guide with the addition of the below:\n",
    "\n",
    "- If no path is given, it defaults to: `~/Datasets/QuoraQuestionPairs/quora_data.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692ce11-bc1e-46ae-ba7b-44ba0e10cbff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
