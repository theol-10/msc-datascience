{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673057b6-3c5b-4c23-9066-72842d823bfa",
   "metadata": {},
   "source": [
    "**Baseline model**\n",
    "\n",
    "Extracts only basic features (jaccard similarity)\n",
    "\n",
    "Trains a Logistic Regression model on this basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16798ff7-3526-4472-84f3-9aa62e3480ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SpaCy model 'en_core_web_md'...\n",
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Model saved to models/logistic_basic.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from utils import (\n",
    "    load_and_split_data,\n",
    "    extract_basic_features,\n",
    "    train_logistic_model\n",
    ")\n",
    "\n",
    "import spacy\n",
    "from utils import nlp as utils_nlp\n",
    "\n",
    "# Ensuring SpaCy model is loaded and assigned to utils\n",
    "# as it was not possible to include it in environment.ysl\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "except OSError:\n",
    "    print(\"Downloading SpaCy model 'en_core_web_md'...\")\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_md\")\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Assign to utils\n",
    "import utils\n",
    "utils.nlp = nlp\n",
    "\n",
    "\n",
    "#Load and Split data\n",
    "\n",
    "train_df, val_df, test_df = load_and_split_data()\n",
    "\n",
    "\n",
    "# Feature Extraction\n",
    "\n",
    "X_train = extract_basic_features(train_df)\n",
    "X_val = extract_basic_features(val_df)\n",
    "\n",
    "y_train = train_df['is_duplicate']\n",
    "y_val = val_df['is_duplicate']\n",
    "\n",
    "\n",
    "# Train Model\n",
    "\n",
    "model = train_logistic_model(X_train, y_train)\n",
    "\n",
    "\n",
    "# Save Model\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model_path = \"models/logistic_basic.pkl\"\n",
    "if not os.path.exists(model_path):\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "else:\n",
    "    print(f\"Model already exists at {model_path} , not saving\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d2b0a-c34c-481b-9a4b-8ec4fadff2dc",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "**Improved baseline model**\n",
    "\n",
    "Uses the full extract_improved_features() with all 7 features: \n",
    "jaccard, len_diff, tfidf_cosine, levenshtein, shared_bigrams, avg_word_len_diff, spacy_cosine\n",
    "\n",
    "Trains another Logistic Regression model, but now including the full feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191d3f4c-b75a-4cd5-ae34-8f84d053c182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/logistic_improved.pkl\n",
      "TF-IDF Vectorizer saved to models/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from utils import (\n",
    "    load_and_split_data,\n",
    "    extract_improved_features,\n",
    "    train_logistic_model\n",
    ")\n",
    "\n",
    "\n",
    "#Load and Split data\n",
    "\n",
    "train_df, val_df, test_df = load_and_split_data()\n",
    "\n",
    "\n",
    "# Extract Improved Features\n",
    "\n",
    "X_train, tfidf_vectorizer = extract_improved_features(train_df)\n",
    "y_train = train_df['is_duplicate']\n",
    "\n",
    "X_val, _ = extract_improved_features(val_df, tfidf_vectorizer)\n",
    "y_val = val_df['is_duplicate']\n",
    "\n",
    "\n",
    "# Train Model\n",
    "\n",
    "model = train_logistic_model(X_train, y_train)\n",
    "\n",
    "\n",
    "# Save Model and TF-IDF Vectorizer\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "model_path = \"models/logistic_improved.pkl\"\n",
    "vectorizer_path = \"models/tfidf_vectorizer.pkl\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "else:\n",
    "    print(f\"Model already exists at {model_path}..not saving.\")\n",
    "\n",
    "if not os.path.exists(vectorizer_path):\n",
    "    joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "    print(f\"TF-IDF Vectorizer saved to {vectorizer_path}\")\n",
    "else:\n",
    "    print(f\"Vectorizer already exists at {vectorizer_path}..not saving.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5704667a-d2c1-433c-a296-1708e83bd480",
   "metadata": {},
   "source": [
    "---------\n",
    "**Grid Search for Best Models (Logistic + Random Forest)**\n",
    " \n",
    "Extracts the same 7 improved features\n",
    "\n",
    "Defines hyperparameter grids for: \n",
    "- LogisticRegression (C=[0.1, 1, 10])\n",
    "- RandomForestClassifier (n_estimators= [50, 100], max_depth=[None, 10])\n",
    "\n",
    "Uses GridSearchCV with 3-fold CV to find the best hyperparameters for each model (based on ROC AUC)\n",
    "\n",
    "Saves both best models and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6f1e21-3791-4588-bd34-fc1ec0820e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for best logistic model.\n",
      "Best AUC for logistic: 0.7763\n",
      "Best params: {'classifier__C': 10}\n",
      "\n",
      "Searching for best random_forest model.\n",
      "Best AUC for random_forest: 0.8174\n",
      "Best params: {'classifier__max_depth': None, 'classifier__n_estimators': 100}\n",
      "Saved logistic model to models/logistic_model.pkl\n",
      "Saved random_forest model to models/random_forest_model.pkl\n",
      "Saved TF-IDF vectorizer to models/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from utils import (\n",
    "    load_and_split_data,\n",
    "    extract_improved_features\n",
    ")\n",
    "\n",
    "\n",
    "# Load Data\n",
    "\n",
    "train_df, val_df, test_df = load_and_split_data()\n",
    "X_train, tfidf_vectorizer = extract_improved_features(train_df)\n",
    "y_train = train_df['is_duplicate']\n",
    "\n",
    "\n",
    "# Define Classifiers and Grid\n",
    "\n",
    "models = {\n",
    "    \"logistic\": {\n",
    "        \"model\": LogisticRegression(max_iter=200),\n",
    "        \"params\": {\n",
    "            \"classifier__C\": [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"classifier__n_estimators\": [50, 100],\n",
    "            \"classifier__max_depth\": [None, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Grid search\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for name, entry in models.items():\n",
    "    print(f\"\\nSearching for best {name} model.\")\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"classifier\", entry[\"model\"])\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(pipe, entry[\"params\"], cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best AUC for {name}: {grid.best_score_:.4f}\")\n",
    "    print(f\"Best params: {grid.best_params_}\")\n",
    "    best_models[name] = grid.best_estimator_\n",
    "\n",
    "\n",
    "#save best models\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    model_path = f\"models/{name}_model.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Saved {name} model to {model_path}\")\n",
    "\n",
    "# Save TF-IDF vectorizer once\n",
    "vectorizer_path = \"models/tfidf_vectorizer.pkl\"\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "print(f\"Saved TF-IDF vectorizer to {vectorizer_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
